<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Practical 5 General Linear Models | H2 Data Science Practical Series</title>
  <meta name="description" content="Handbook for the H2 Data Science practicals." />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Practical 5 General Linear Models | H2 Data Science Practical Series" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://brightspace.uhi.ac.uk/d2l/home/341332/figs/cover_short.png" />
  <meta property="og:description" content="Handbook for the H2 Data Science practicals." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Practical 5 General Linear Models | H2 Data Science Practical Series" />
  
  <meta name="twitter:description" content="Handbook for the H2 Data Science practicals." />
  <meta name="twitter:image" content="https://brightspace.uhi.ac.uk/d2l/home/341332/figs/cover_short.png" />




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="t-test.html"/>
<link rel="next" href="multivariate.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">H2 Data Science Practical Series</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="overview.html"><a href="overview.html"><i class="fa fa-check"></i>Overview</a>
<ul>
<li class="chapter" data-level="0.1" data-path="overview.html"><a href="overview.html#practical-sessions"><i class="fa fa-check"></i><b>0.1</b> Practical sessions</a></li>
<li class="chapter" data-level="0.2" data-path="overview.html"><a href="overview.html#assessments"><i class="fa fa-check"></i><b>0.2</b> Assessments</a></li>
<li class="chapter" data-level="0.3" data-path="overview.html"><a href="overview.html#R_intro"><i class="fa fa-check"></i><b>0.3</b> Getting started in R</a>
<ul>
<li class="chapter" data-level="0.3.1" data-path="overview.html"><a href="overview.html#rstudio-project"><i class="fa fa-check"></i><b>0.3.1</b> RStudio Project</a></li>
<li class="chapter" data-level="0.3.2" data-path="overview.html"><a href="overview.html#rstudio-settings"><i class="fa fa-check"></i><b>0.3.2</b> RStudio Settings</a></li>
<li class="chapter" data-level="0.3.3" data-path="overview.html"><a href="overview.html#r-packages-and-libraries"><i class="fa fa-check"></i><b>0.3.3</b> R packages and libraries</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="EDA.html"><a href="EDA.html"><i class="fa fa-check"></i><b>1</b> Displaying and summarising data</a>
<ul>
<li class="chapter" data-level="1.1" data-path="EDA.html"><a href="EDA.html#basic-data-exploration"><i class="fa fa-check"></i><b>1.1</b> Basic data exploration</a></li>
<li class="chapter" data-level="1.2" data-path="EDA.html"><a href="EDA.html#graphical-methods-for-displaying-data"><i class="fa fa-check"></i><b>1.2</b> Graphical methods for displaying data</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="EDA.html"><a href="EDA.html#scatter-plot"><i class="fa fa-check"></i><b>1.2.1</b> Scatter plot</a></li>
<li class="chapter" data-level="1.2.2" data-path="EDA.html"><a href="EDA.html#boxplots"><i class="fa fa-check"></i><b>1.2.2</b> Boxplots</a></li>
<li class="chapter" data-level="1.2.3" data-path="EDA.html"><a href="EDA.html#line-plots"><i class="fa fa-check"></i><b>1.2.3</b> Line plots</a></li>
<li class="chapter" data-level="1.2.4" data-path="EDA.html"><a href="EDA.html#histograms"><i class="fa fa-check"></i><b>1.2.4</b> Histograms</a></li>
<li class="chapter" data-level="1.2.5" data-path="EDA.html"><a href="EDA.html#bar-graphs"><i class="fa fa-check"></i><b>1.2.5</b> Bar graphs</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="EDA.html"><a href="EDA.html#summary-statistics"><i class="fa fa-check"></i><b>1.3</b> Summary statistics</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="EDA.html"><a href="EDA.html#which-measure-of-central-tendency-to-use"><i class="fa fa-check"></i><b>1.3.1</b> Which measure of central tendency to use</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="EDA.html"><a href="EDA.html#conclusions"><i class="fa fa-check"></i><b>1.4</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="bin_pois.html"><a href="bin_pois.html"><i class="fa fa-check"></i><b>2</b> Binomial &amp; Poisson distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="bin_pois.html"><a href="bin_pois.html#the-binomial-distribution"><i class="fa fa-check"></i><b>2.1</b> The Binomial distribution</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="bin_pois.html"><a href="bin_pois.html#bernoulli-trials"><i class="fa fa-check"></i><b>2.1.1</b> Bernoulli trials</a></li>
<li class="chapter" data-level="2.1.2" data-path="bin_pois.html"><a href="bin_pois.html#the-binomial-distribution-1"><i class="fa fa-check"></i><b>2.1.2</b> The binomial distribution</a></li>
<li class="chapter" data-level="2.1.3" data-path="bin_pois.html"><a href="bin_pois.html#binomial-distributions-by-hand"><i class="fa fa-check"></i><b>2.1.3</b> Binomial distributions by hand</a></li>
<li class="chapter" data-level="2.1.4" data-path="bin_pois.html"><a href="bin_pois.html#binomial-distributions-in-r"><i class="fa fa-check"></i><b>2.1.4</b> Binomial distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="bin_pois.html"><a href="bin_pois.html#the-poisson-distribution"><i class="fa fa-check"></i><b>2.2</b> The Poisson distribution</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="bin_pois.html"><a href="bin_pois.html#poisson-distributions-by-hand"><i class="fa fa-check"></i><b>2.2.1</b> Poisson distributions by hand</a></li>
<li class="chapter" data-level="2.2.2" data-path="bin_pois.html"><a href="bin_pois.html#poisson-distributions-in-r"><i class="fa fa-check"></i><b>2.2.2</b> Poisson distributions in R</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="bin_pois.html"><a href="bin_pois.html#the-poisson-approximation-of-the-binomial-model"><i class="fa fa-check"></i><b>2.3</b> The Poisson approximation of the binomial model</a></li>
<li class="chapter" data-level="2.4" data-path="bin_pois.html"><a href="bin_pois.html#conclusions-1"><i class="fa fa-check"></i><b>2.4</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="normal.html"><a href="normal.html"><i class="fa fa-check"></i><b>3</b> Normal distribution</a>
<ul>
<li class="chapter" data-level="3.1" data-path="normal.html"><a href="normal.html#using-the-normal-probability-distributions"><i class="fa fa-check"></i><b>3.1</b> Using the normal probability distributions</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="normal.html"><a href="normal.html#using-r-to-calculate-areas-under-the-normal-curve"><i class="fa fa-check"></i><b>3.1.1</b> Using R to calculate areas under the normal curve</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="normal.html"><a href="normal.html#normal-model-adequacy"><i class="fa fa-check"></i><b>3.2</b> Normal model adequacy</a></li>
<li class="chapter" data-level="3.3" data-path="normal.html"><a href="normal.html#calculating-quantiles-in-the-normal-distribution"><i class="fa fa-check"></i><b>3.3</b> Calculating quantiles in the normal distribution</a></li>
<li class="chapter" data-level="3.4" data-path="normal.html"><a href="normal.html#testing-for-normality"><i class="fa fa-check"></i><b>3.4</b> Testing for normality</a></li>
<li class="chapter" data-level="3.5" data-path="normal.html"><a href="normal.html#transformations"><i class="fa fa-check"></i><b>3.5</b> Data transformations</a></li>
<li class="chapter" data-level="3.6" data-path="normal.html"><a href="normal.html#functions-in-r"><i class="fa fa-check"></i><b>3.6</b> Functions in R</a></li>
<li class="chapter" data-level="3.7" data-path="normal.html"><a href="normal.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>3.7</b> The central limit theorem</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="normal.html"><a href="normal.html#the-distribution-of-means-from-various-data-distributions"><i class="fa fa-check"></i><b>3.7.1</b> The distribution of means from various data distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="normal.html"><a href="normal.html#the-standard-error-of-the-mean"><i class="fa fa-check"></i><b>3.8</b> The standard error of the mean</a></li>
<li class="chapter" data-level="3.9" data-path="normal.html"><a href="normal.html#normal-approximations-for-other-distributions"><i class="fa fa-check"></i><b>3.9</b> Normal approximations for other distributions</a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="normal.html"><a href="normal.html#the-normal-approximation-of-the-poisson-distribution"><i class="fa fa-check"></i><b>3.9.1</b> The Normal approximation of the Poisson distribution</a></li>
<li class="chapter" data-level="3.9.2" data-path="normal.html"><a href="normal.html#the-normal-approximation-of-the-binomial-distribution"><i class="fa fa-check"></i><b>3.9.2</b> The normal approximation of the binomial distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="normal.html"><a href="normal.html#conclusions-2"><i class="fa fa-check"></i><b>3.10</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="t-test.html"><a href="t-test.html"><i class="fa fa-check"></i><b>4</b> t-tests &amp; confidence intervals</a>
<ul>
<li class="chapter" data-level="4.1" data-path="t-test.html"><a href="t-test.html#single-sample-t-tests"><i class="fa fa-check"></i><b>4.1</b> Single sample t-tests</a></li>
<li class="chapter" data-level="4.2" data-path="t-test.html"><a href="t-test.html#confidence-intervals"><i class="fa fa-check"></i><b>4.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="4.3" data-path="t-test.html"><a href="t-test.html#comparing-means-two-sample-t-tests"><i class="fa fa-check"></i><b>4.3</b> Comparing means (two-sample t tests)</a></li>
<li class="chapter" data-level="4.4" data-path="t-test.html"><a href="t-test.html#non-parametric-tests"><i class="fa fa-check"></i><b>4.4</b> Non-parametric Tests</a></li>
<li class="chapter" data-level="4.5" data-path="t-test.html"><a href="t-test.html#conclusions-3"><i class="fa fa-check"></i><b>4.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glm.html"><a href="glm.html"><i class="fa fa-check"></i><b>5</b> General Linear Models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="glm.html"><a href="glm.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.1</b> Analysis of variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="glm.html"><a href="glm.html#anova-in-r"><i class="fa fa-check"></i><b>5.1.1</b> ANOVA in R</a></li>
<li class="chapter" data-level="5.1.2" data-path="glm.html"><a href="glm.html#one-way-anova"><i class="fa fa-check"></i><b>5.1.2</b> One-way ANOVA</a></li>
<li class="chapter" data-level="5.1.3" data-path="glm.html"><a href="glm.html#two-way-anova"><i class="fa fa-check"></i><b>5.1.3</b> Two-way ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="glm.html"><a href="glm.html#regression"><i class="fa fa-check"></i><b>5.2</b> Regression</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="glm.html"><a href="glm.html#overview-1"><i class="fa fa-check"></i><b>5.2.1</b> Overview</a></li>
<li class="chapter" data-level="5.2.2" data-path="glm.html"><a href="glm.html#linear-regression-in-r"><i class="fa fa-check"></i><b>5.2.2</b> Linear regression in R</a></li>
<li class="chapter" data-level="5.2.3" data-path="glm.html"><a href="glm.html#plotting-the-regression-line-and-confidence-intervals"><i class="fa fa-check"></i><b>5.2.3</b> Plotting the regression line and confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="glm.html"><a href="glm.html#conclusions-4"><i class="fa fa-check"></i><b>5.3</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate.html"><a href="multivariate.html"><i class="fa fa-check"></i><b>6</b> Multivariate analysis</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multivariate.html"><a href="multivariate.html#multivariate-analysis-in-r"><i class="fa fa-check"></i><b>6.1</b> Multivariate analysis in R</a></li>
<li class="chapter" data-level="6.2" data-path="multivariate.html"><a href="multivariate.html#diversity-indices"><i class="fa fa-check"></i><b>6.2</b> Diversity indices</a></li>
<li class="chapter" data-level="6.3" data-path="multivariate.html"><a href="multivariate.html#nmds-on-real-data"><i class="fa fa-check"></i><b>6.3</b> NMDS on real data</a></li>
<li class="chapter" data-level="6.4" data-path="multivariate.html"><a href="multivariate.html#principal-components-analysis-pca"><i class="fa fa-check"></i><b>6.4</b> Principal components analysis (PCA)</a></li>
<li class="chapter" data-level="6.5" data-path="multivariate.html"><a href="multivariate.html#conclusions-5"><i class="fa fa-check"></i><b>6.5</b> Conclusions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>7</b> Appendix</a>
<ul>
<li class="chapter" data-level="7.1" data-path="appendix.html"><a href="appendix.html#probability"><i class="fa fa-check"></i><b>7.1</b> Probability</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="appendix.html"><a href="appendix.html#probability-for-equally-likely-outcomes"><i class="fa fa-check"></i><b>7.1.1</b> Probability for equally likely outcomes</a></li>
<li class="chapter" data-level="7.1.2" data-path="appendix.html"><a href="appendix.html#multiplication-and-addition"><i class="fa fa-check"></i><b>7.1.2</b> Multiplication and addition</a></li>
<li class="chapter" data-level="7.1.3" data-path="appendix.html"><a href="appendix.html#bayes-theorem"><i class="fa fa-check"></i><b>7.1.3</b> Bayes’ theorem</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="appendix.html"><a href="appendix.html#univariate-statistics"><i class="fa fa-check"></i><b>7.2</b> Univariate statistics</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="appendix.html"><a href="appendix.html#mean"><i class="fa fa-check"></i><b>7.2.1</b> Mean</a></li>
<li class="chapter" data-level="7.2.2" data-path="appendix.html"><a href="appendix.html#median-quartiles-and-adjacent-values"><i class="fa fa-check"></i><b>7.2.2</b> Median, quartiles and adjacent values</a></li>
<li class="chapter" data-level="7.2.3" data-path="appendix.html"><a href="appendix.html#the-sum-of-squares"><i class="fa fa-check"></i><b>7.2.3</b> The sum of squares</a></li>
<li class="chapter" data-level="7.2.4" data-path="appendix.html"><a href="appendix.html#measures-of-dispersion"><i class="fa fa-check"></i><b>7.2.4</b> Measures of dispersion</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="appendix.html"><a href="appendix.html#the-binomial-distribution-2"><i class="fa fa-check"></i><b>7.3</b> The Binomial distribution</a></li>
<li class="chapter" data-level="7.4" data-path="appendix.html"><a href="appendix.html#the-poisson-distribution-1"><i class="fa fa-check"></i><b>7.4</b> The Poisson distribution</a></li>
<li class="chapter" data-level="7.5" data-path="appendix.html"><a href="appendix.html#z-scores"><i class="fa fa-check"></i><b>7.5</b> Z scores</a></li>
<li class="chapter" data-level="7.6" data-path="appendix.html"><a href="appendix.html#samples-taken-from-a-population"><i class="fa fa-check"></i><b>7.6</b> Samples taken from a population</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="appendix.html"><a href="appendix.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>7.6.1</b> Standard error of the mean</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="appendix.html"><a href="appendix.html#the-t-distribution"><i class="fa fa-check"></i><b>7.7</b> The t distribution</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="appendix.html"><a href="appendix.html#the-one-sample-t-test"><i class="fa fa-check"></i><b>7.7.1</b> The one sample t-test</a></li>
<li class="chapter" data-level="7.7.2" data-path="appendix.html"><a href="appendix.html#confidence-intervals-for-sample-means"><i class="fa fa-check"></i><b>7.7.2</b> Confidence intervals for sample means</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="appendix.html"><a href="appendix.html#anova"><i class="fa fa-check"></i><b>7.8</b> ANOVA</a></li>
<li class="chapter" data-level="7.9" data-path="appendix.html"><a href="appendix.html#regression-correlation"><i class="fa fa-check"></i><b>7.9</b> Regression &amp; correlation</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">H2 Data Science Practical Series</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="glm" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Practical 5</span> General Linear Models<a href="glm.html#glm" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>General linear models are a key member of the generalised linear modelling family and they are among the most widely used and reported models in the marine science literature, particularly biology. This course focuses on two subsets of linear models: ANOVA and regression. ANOVA and regression are typically used for different data modelling scenarios: ANOVA when you’ve got a categorical predictor variable(s) and regression when your predictor is continuous.</p>
<div id="analysis-of-variance-anova" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Analysis of variance (ANOVA)<a href="glm.html#analysis-of-variance-anova" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>ANOVA is a widely used modelling approach that enables you to compare means and put confidence intervals on the differences between those means. For a predictor with only two categories, ANOVA is identical to the 2-sample t-test, so we’ll just use ANOVA.</p>
<p>When you see “analysis of variance”, think “analysis of means”. In an ANOVA, we analyse the variance in the data in order to compare the means of different groups. In an ANOVA, we compare means by determining the ratio of [the variance between treatments and the overall mean (large black arrows in Fig. <a href="#fig:var-sources"><strong>??</strong></a>)] and [the variance within treatments (sum of the dotted arrows in Fig. <a href="#fig:var-sources"><strong>??</strong></a>)]. The black line under the red dots in Fig. <a href="#fig:var-sources"><strong>??</strong></a> shows the actual data distribution and the actual parameters for mean values (50 and 150 cm for A and B respectively). You then take samples from A and B (n=4 in this example) and, from these, derive your parameter estimates for the mean of each group and the overall mean.</p>
<p>In Fig. <a href="#fig:var-sources"><strong>??</strong></a> below you can see that the solid black arrows are much larger than the dotted ones leading you to think that the chance that these two samples are drawn from the same population (with a value of the overall mean) as very unlikely. Make sure you understand Fig. <a href="#fig:var-sources"><strong>??</strong></a> (more detail in the ANOVA lecture).</p>
<p>In most circumstances you know that the means that you are comparing with ANOVA are different (i.e. that testing a null hypothesis of no difference isn’t useful). ANOVA allows you to put confidence intervals around differences between means, or groups of means.</p>
<div id="anova-in-r" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> ANOVA in R<a href="glm.html#anova-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are numerous variations on the theme of ANOVA. We cover one-way ANOVA and we mention two-way ANOVA with and without replication. The objective of ANOVA is to establish the size of the difference (called the ‘effect size’) between different groups (e.g., treatments or locations) and put a confidence interval on those differences.</p>
</div>
<div id="one-way-anova" class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> One-way ANOVA<a href="glm.html#one-way-anova" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One-way ANOVA is a procedure we use to estimate the magnitude of differences between means of <span class="math inline">\(\geq\)</span> 2 groups. We also use it to put confidence intervals on those differences.</p>
<p>The first example data is the yield in <span class="math inline">\(\mu g\)</span> C <span class="math inline">\(ml^{-1}\)</span> of a species of microalgae (<em>Isochrysis galbana</em>) in laboratory culture exposed to three light levels (low, medium and high). We are interested in these particular light levels because they represent the means of winter, spring, and summer Scottish sun intensity. The data are in worksheet ‘Microalgae’.</p>
<p>Note: the function to conduct an ANOVA is <code>aov()</code>. The function <code>anova()</code> converts various statistical model outputs to the standard ANOVA-table output (including any from the GLM family).</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="glm.html#cb186-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(readxl)</span>
<span id="cb186-2"><a href="glm.html#cb186-2" aria-hidden="true" tabindex="-1"></a>algae_wide_df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">&quot;data/practical_5.xlsx&quot;</span>, <span class="at">sheet =</span> <span class="st">&quot;Microalgae&quot;</span>)</span>
<span id="cb186-3"><a href="glm.html#cb186-3" aria-hidden="true" tabindex="-1"></a><span class="co"># check these data as usual</span></span></code></pre></div>
<p><em>Q158. What is your objective in this type of experiment? What are you interested in estimating?</em></p>
<p><em>Q159. What assumptions should be met prior to undertaking parametric ANOVA?</em></p>
<p><em>Q160. Under which circumstances could you begin to relax the assumption that the data are normally distributed (think central limit theorem)?</em></p>
<p><em>Q161. Given your sample size can we assume normality of means?</em></p>
<p><em>Q162. Are the data normally distributed (be careful how you word your answer to this question, see the following question)?</em></p>
<p><em>Q163. Is it reasonable to assume that these data are drawn from a population that is normally distributed?</em></p>
<p>We can check the homoscedasticity assumption using Bartlett’s test. Before we can use this test we need to rearrange the data so that the data is in a single indexed column. We’ll use the <em>tidyverse</em> as before.</p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="glm.html#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb187-2"><a href="glm.html#cb187-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(algae_wide_df, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##     low medium  high
##   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;
## 1  13.1   12    14.2
## 2  11.5   11.5  13.1</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="glm.html#cb189-1" aria-hidden="true" tabindex="-1"></a>algae_df <span class="ot">&lt;-</span> algae_wide_df <span class="sc">|&gt;</span></span>
<span id="cb189-2"><a href="glm.html#cb189-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="st">&quot;Treatment&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;Yield&quot;</span>)</span>
<span id="cb189-3"><a href="glm.html#cb189-3" aria-hidden="true" tabindex="-1"></a><span class="fu">glimpse</span>(algae_df, <span class="at">width=</span><span class="dv">80</span>)</span></code></pre></div>
<pre><code>## Rows: 15
## Columns: 2
## $ Treatment &lt;chr&gt; &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;, &quot;low&quot;, &quot;medium&quot;, &quot;high&quot;, &quot;low&quot;, &quot;me…
## $ Yield     &lt;dbl&gt; 13.07599, 12.00000, 14.20000, 11.53923, 11.50000, 13.10000, …</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="glm.html#cb191-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bartlett.test</span>(Yield <span class="sc">~</span> Treatment, <span class="at">data =</span> algae_df) <span class="co">#?bartlett.test</span></span></code></pre></div>
<pre><code>## 
##  Bartlett test of homogeneity of variances
## 
## data:  Yield by Treatment
## Bartlett&#39;s K-squared = 2.8413, df = 2, p-value = 0.2416</code></pre>
<p><em>Q164. With regard to Bartlett’s test, is the assumption of homogeneity reasonable?</em></p>
<p>A more elegant (and much better) way of checking model assumptions is to check residual patterns. A ‘residual’ is the difference between an actual data value and that predicted by the model. Here we have randomly assigned five cultures each of the same species to three specific treatments (light levels).</p>
<p><em>Q165. What type of experiment is this (how many factors, are they fixed or random)?</em></p>
<p>Next to conduct the analysis:</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="glm.html#cb193-1" aria-hidden="true" tabindex="-1"></a>algae_aov <span class="ot">&lt;-</span> <span class="fu">aov</span>(Yield <span class="sc">~</span> Treatment, <span class="at">data =</span> algae_df) <span class="co"># ?aov</span></span></code></pre></div>
<p>Before we look at the output, let’s assess the assumptions using the residuals. The default residual plots created by R are shown in Fig. <a href="glm.html#fig:algae-aov">5.1</a> and enables us to rapidly assess whether the model assumptions are reasonable.</p>
<div class="sourceCode" id="cb194"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb194-1"><a href="glm.html#cb194-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)) </span>
<span id="cb194-2"><a href="glm.html#cb194-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(algae_aov) </span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:algae-aov"></span>
<img src="_main_files/figure-html/algae-aov-1.png" alt="Residual plots from one-way ANOVA." width="50%" height="50%" />
<p class="caption">
Figure 5.1: Residual plots from one-way ANOVA.
</p>
</div>
<p><strong>Interpretation of residual patterns:</strong></p>
<ul>
<li><strong>Upper left:</strong> Residuals v. fitted. This is the residual values against the fitted values. The fitted values are the means of the three groups (remember that ANOVA is about comparing means). The spread for the lower values (low and medium light) is higher than for the high light so this might make us consider the homoscedasticity assumption.<br />
</li>
<li><strong>Upper right:</strong> Normal Q-Q plot. This assesses the normality assumption. The points (each point is an observation) lie around the straight line so this assumption is reasonable. Note that general linear models assume that the means of groups are normally distributed, and this always applies when the means are based on large sample sizes (roughly <span class="math inline">\(n &gt; 30\)</span>)). When <span class="math inline">\(n &lt; 30\)</span>, you should check that the distribution of the residuals is reasonably ‘normal’.<br />
</li>
<li><strong>Lower left:</strong> Scale-location. This specifically looks to assess whether residuals increase with fitted values, which is a common issue in these types of analysis. In this case, the scale decreases with fitted value. This is similar to the Upper Left plot, but with <code>sqrt(abs(standardized_residuals))</code> on the y-axis instead of just <code>residuals</code> to focus just on the magnitude of the residuals.<br />
</li>
<li><strong>Lower right:</strong> Constant leverage, residuals vs. factor levels. This indicates how each treatment is fitted (i.e. the residuals associated with each treatment). You might be concerned if one particular treatment was associated with extremely high residuals (outliers). R automatically identifies potential outliers (8, 11, and 13 in this case) for you to further assess. In this case there is nothing in particular to worry about.</li>
</ul>
<p>The residual plots allow you to investigate different aspects of the data and the how their assumptions are met. The interpretation of the plots overlaps in the sense that the same issue might be apparent in several of the plots.</p>
<p><em>Q166. What are the ‘fitted values’ for an ANOVA?</em></p>
<p><em>Q167. Are your effects fixed or random?</em></p>
<p><em>Q168. Assuming you have chosen</em> <span class="math inline">\(\alpha = 0.05\)</span><em>, what might you be interested in going on to test next? Hint: you are testing to see whether the means of three populations are different.</em></p>
<p>Everything looks ok, so we can then look at the results of the ANOVA.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="glm.html#cb195-1" aria-hidden="true" tabindex="-1"></a><span class="co"># anova(algae_aov) # outputs an anova-type table, but unnecessary with aov()</span></span>
<span id="cb195-2"><a href="glm.html#cb195-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(algae_aov)</span></code></pre></div>
<pre><code>##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## Treatment    2 10.050   5.025   6.487 0.0123 *
## Residuals   12  9.296   0.775                 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Reporting that there are ‘significant’ differences between means is not enough. What your readers should be interested in is what the differences between the means actually are, and how confident you are in your assessment. This can be provided by the Tukey test in R.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="glm.html#cb197-1" aria-hidden="true" tabindex="-1"></a>algae_grp_diffs <span class="ot">&lt;-</span> <span class="fu">TukeyHSD</span>(<span class="at">x =</span> algae_aov, <span class="at">conf.level =</span> <span class="fl">0.95</span>) </span>
<span id="cb197-2"><a href="glm.html#cb197-2" aria-hidden="true" tabindex="-1"></a><span class="co"># HSD stands for &#39;honestly significant difference&#39;</span></span>
<span id="cb197-3"><a href="glm.html#cb197-3" aria-hidden="true" tabindex="-1"></a>algae_grp_diffs</span></code></pre></div>
<pre><code>##   Tukey multiple comparisons of means
##     95% family-wise confidence level
## 
## Fit: aov(formula = Yield ~ Treatment, data = algae_df)
## 
## $Treatment
##                    diff       lwr        upr     p adj
## low-high    -1.68922461 -3.174304 -0.2041449 0.0260570
## medium-high -1.78000000 -3.265080 -0.2949203 0.0194474
## medium-low  -0.09077539 -1.575855  1.3943043 0.9854641</code></pre>
<p>You can see that the mean yield at the high light level is higher than at both the low and medium: the 95% confidence interval of the difference in comparing high and low light levels are 1.69 (0.205, 3.17) <span class="math inline">\(\mu g\)</span> C <span class="math inline">\(ml^{-1}\)</span>. (I’ve inverted the results so the the difference is seen as positive (high - low rather than low - high)). This confidence interval is much more important than any P-values and you should report both (CI because it is useful, P value by convention).</p>
</div>
<div id="two-way-anova" class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Two-way ANOVA<a href="glm.html#two-way-anova" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>You’ve had a look at one-way ANOVA (i.e., one predictor), which is a good starting point. However, in nature you often find numerous factors combine to influence an outcome. This is called an ‘interaction’. Two-way ANOVA allows you to investigate the nature of this interaction term. You can also get three-way ANOVA and more, but these get logistically challenging because you need to replicate across each level. The interpretation also gets increasingly difficult. You need to be aware of the existence of two-way ANOVA and what it offers, and how to interpret simple graphics (below), but we do not cover implementation of two-way ANOVA.</p>
<p>In Fig. <a href="#fig:interaction"><strong>??</strong></a> we have the outcome of an experiment. Each dot on the plot represents the mean Response (e.g. growth) of a number of replicates, subject to the combination of Temperature (cold and hot) and Nutrient (N and P). We are interested in the main effects (Temp and Nutrient) and their interaction (Temp * Nutrient) In panel A, there is no effect of Temp on the Response (the lines between Cold and Hot are horizontal), but there is a main effect of Nutrient (P is higher than N). In B, there is an effect of Temp (Hot is, on average higher than Cold) but there is also an interaction as the effect of Hot is more for P than for N (where it has no effect in this example). In C, the interaction is stronger compared with B. In D, there are no treatment main effects because mean Cold = mean Hot and mean N = mean P, but there is a very strong interaction effect; the effect of Temp is reversed by Nutrient, so that the level of Nutrient (N or P) determines the effect of Temp. When it is Cold the Response is high for Nutrient P and low for Nutrient N, when it is Hot, the Response is low for Nutrient P and high for Nutrient N (but the average for hot=cold, and average for N=P)</p>
<hr />
</div>
</div>
<div id="regression" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Regression<a href="glm.html#regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Correlation and regression are used to examine the strength of association between two variables. In correlation, both variables are measured (and therefore associated with measurement error). In regression, one variable is fixed (by the experimenter) and is asssumed to have no ‘error’ associated with it and the other, called the ‘response variable’, is measured (so has measurement error). You must be able to distinguish which of correlation or regression analyses are most appropriate.</p>
<p>Correlation analysis is used to measure association, where you are not attempting to formally link cause-and-effect. Regression analysis is generally used where you have experimentally manipulated the fixed factor and are looking at the response in another factor. Causation is implicit in inferential regression analysis (correlation analysis is often used in ‘exploratory’ data analysis where any link between cause-and-effect is inherently more speculative).</p>
<p>The media often misreport science because it is difficult to resist the impulse to attribute causation. An overwhelming number of spurious correlations (i.e., those <em>clearly</em> having no causal relationship) are documented on <a href="https://tylervigen.com/spurious-correlations">tylervigen.com</a>.</p>
<div id="overview-1" class="section level3 hasAnchor" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Overview<a href="glm.html#overview-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Regression is at the heart of linear models. ANOVA and t-tests are, basically, special cases of linear regression models. The regression coefficient is a measure of the strength of the relationship between the dependent variable (the one you measure) and the independent variable (the one you fix like a fixed factor in ANOVA). The regression coefficient is denoted by <span class="math inline">\(R^2\)</span> compared with <span class="math inline">\(r\)</span> in correlation. The regression coefficient <span class="math inline">\(R^2\)</span> ranges from 0 to 1 (unlike <span class="math inline">\(r\)</span> which ranges from -1 to 1). A value <span class="math inline">\(R^2 = 0\)</span> indicates no relationship to the independent variable while <span class="math inline">\(R^2=1\)</span> indicates that the independent variable is entirely responsible for the variability in the measured variable.</p>
<p>As usual, null hypothesis significance testing is often applied to regression statistics. As usual, the null hypothesis being tested is usually “there is no functional relationship between the response and the predictor” and this is usually conceptually nonsense. In conducting regression analysis, your objective is to quantify to the most appropriate precision and accuracy possible the relationship between X (the aspect you control, the predictor, plotted on the X axis) and Y (the variable you measure, the response, plotted on the Y axis). Your objective is to quanitfy this relationship, put confidence intervals on it, and then interpret your findings in relation to the objectives of the study and in relation to other research.</p>
<p><em>Q169. Sketch a graph demonstrating the null hypothesis (of no relationship) in regression analysis.</em>
</p>
<p>Let us now consider an example in which cause and effect does exist. The data in worksheet ‘Regression1’ shows the weight loss in <em>Tribolium confusum</em>, the confused flour beetle, at different relative humidities (data from Sokal and Rohlf, 1995). The relative humidity (RH) to which the beetles are exposed can be fixed and the weight loss (via evaporative losses) of the beetles then assessed. There is no way that the null hypothesis can be true in this case: humidity will obviously influence weight loss in beetles.</p>
<p><em>Q170. In this case, what is your response variable (what are you measuring) and your predictor (i.e. what is it that you are manipulating to determine the extent of the response)?</em></p>
<p><em>Q171. Plot the data in R and check your prediction. In this case, the predictor must be displayed on the x-axis and the response must be on the y-axis.</em></p>
<p>We are interested in whether the whole data set can be usefully represented by a linear regression relationship. We wish to estimate the relationship, and put a confidence interval on our estimate. Common sense tells us that there <em>is</em> some sort of relationship (testing a null hypothesis is not very useful) but it might go in either direction (positive or negative) and we don’t know the strength (i.e. slope) of that relationship.</p>
</div>
<div id="linear-regression-in-r" class="section level3 hasAnchor" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Linear regression in R<a href="glm.html#linear-regression-in-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In R we can use a variety of techniques to conduct linear regression. The easiest is to use <code>lm()</code>. It is worth noting that <code>lm()</code> would also work for all your other general linear models (e.g. ANOVA). They are, in fact, the same model, it is just the default output (and necessary input formatting) that differs. Try reproducing the ANOVAs above with <code>anova(lm(...))</code>.</p>
<p>Import data and begin:</p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="glm.html#cb199-1" aria-hidden="true" tabindex="-1"></a>beetle_df <span class="ot">&lt;-</span> <span class="fu">read_excel</span>(<span class="st">&quot;data/practical_6.xlsx&quot;</span>, <span class="at">sheet =</span> <span class="st">&quot;Beetles&quot;</span>)</span>
<span id="cb199-2"><a href="glm.html#cb199-2" aria-hidden="true" tabindex="-1"></a><span class="co"># inspect the dataframe, then make a scatter plot</span></span>
<span id="cb199-3"><a href="glm.html#cb199-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb199-4"><a href="glm.html#cb199-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(WeightLoss_Mg <span class="sc">~</span> Humidity, <span class="at">data =</span> beetle_df) </span></code></pre></div>
<p><img src="_main_files/figure-html/beetle-scatter-1.png" width="40%" height="50%" style="display: block; margin: auto;" /></p>
<p>An aside on plotting: you can provide <code>plot()</code> with either a vector for the x-axis and a vector for the y-axis (i.e., <code>plot(x_var, y_var)</code>) <em>or</em> you can use a formula, specifying the dataframe (i.e., <code>plot(y ~ x, data=data_df)</code>). Just be aware of which variable is on which axis.</p>
<p>Now we have explored and plotted the data we can conduct the regression analysis.</p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="glm.html#cb200-1" aria-hidden="true" tabindex="-1"></a><span class="co"># weightloss is modelled as (~) a function of humidity</span></span>
<span id="cb200-2"><a href="glm.html#cb200-2" aria-hidden="true" tabindex="-1"></a>beetle_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(WeightLoss_Mg <span class="sc">~</span> Humidity, <span class="at">data =</span> beetle_df) </span>
<span id="cb200-3"><a href="glm.html#cb200-3" aria-hidden="true" tabindex="-1"></a><span class="co"># beetle_lm</span></span>
<span id="cb200-4"><a href="glm.html#cb200-4" aria-hidden="true" tabindex="-1"></a><span class="co"># str(beetle_lm) # lm outputs are complex structures</span></span></code></pre></div>
<p>Before we go on and interpret the model output we need to assess the model assumptions. This is done in the same way as for ANOVA with the same commands.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb201-1"><a href="glm.html#cb201-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="dv">4</span>,<span class="dv">1</span>,<span class="dv">1</span>)) <span class="co"># set up 4 in 1 plot.</span></span>
<span id="cb201-2"><a href="glm.html#cb201-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(beetle_lm) <span class="co"># plot the regresssion residuals.</span></span></code></pre></div>
<p><img src="_main_files/figure-html/beetle-diag-1.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<p>The small sample size here (<span class="math inline">\(n=9\)</span>) makes a proper analysis of the residuals difficult. The plot should be assessed in the same way as for the ANOVA residuals. Basically, any pattern is bad. The upper left (Residuals v Fitted) doesn’t cause any major concern, thought upper right (Normal QQ) indicates a possible problem. Scale-Location (lower left) is difficult to interpret but no obvious pattern is present. The Residuals v. leverage (lower right) indicates a potential issue as well. A point with a large residual (i.e. where it is very different to that expected by the model) and with a high leverage (i.e. at the extreme ends of the predictors range) has a large Cook’s distance and has a disproportionate effect on the slope and intercept. These points should be examined in more detail.</p>
<p><em>Q172. Which point has the largest Cook’s distance?</em></p>
<p>We will now proceed to looking at the linear regression analysis results on the basis that the residuals do not raise any concerns.</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb202-1"><a href="glm.html#cb202-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(beetle_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = WeightLoss_Mg ~ Humidity, data = beetle_df)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.46397 -0.03437  0.01675  0.07464  0.45236 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  8.704027   0.191565   45.44 6.54e-10 ***
## Humidity    -0.053222   0.003256  -16.35 7.82e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2967 on 7 degrees of freedom
## Multiple R-squared:  0.9745, Adjusted R-squared:  0.9708 
## F-statistic: 267.2 on 1 and 7 DF,  p-value: 7.816e-07</code></pre>
<p>The regression equation of the form <span class="math inline">\(y = a + bx\)</span> can be determined. The regression equation is:</p>
<p><span class="math inline">\(WeightLoss = 8.70 - 0.05322 * humidity\)</span></p>
<p>Common-sense check: the coefficient is negative. As the humidity increases, the weight loss decreases (as expected and shown in the scatter plot).</p>
<p><em>Q173. What is the effect on weight loss of increasing the relative humidity by 10%?</em></p>
<p><em>Q174. What is the weight loss, predicted by the model, when relative humidity is 0%?</em></p>
<p><em>Q175. What does the model suggest the weight loss will be when relative humidity is -50% and +150%? Are these values sensible? What does this tell you about extrapolating beyond the data range in using regression analysis in predictions?</em></p>
<p>The residual error is the variance in y around the line. The <span class="math inline">\(R^2\)</span> is the proportion of this variance that is explained by the regression line. In the current case <span class="math inline">\(R^2 = 0.97\)</span>. This is an extremely high value and indicates that the regression model is extraordinarily good at accounting for the variance in weight loss based on the relative humidity.</p>
<p>The P values allow us to assess if the slope and the intercept are likely different from zero.</p>
<p><em>Q176. Given the very high</em> <span class="math inline">\(R^2\)</span> <em>(and looking at your plot) would you expect the regression model to be significantly better than the null model in explaining the variance in weight loss?</em></p>
<p><em>Q177. With</em> <span class="math inline">\(\alpha = 0.05\)</span><em>, do you reject or accept the null hypothesis? What would you wish to report in relation to the slope coefficient if you were reporting the results from this analysis?</em></p>
<div class="sourceCode" id="cb204"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb204-1"><a href="glm.html#cb204-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(beetle_lm)</span></code></pre></div>
<pre><code>##                   2.5 %      97.5 %
## (Intercept)  8.25104923  9.15700538
## Humidity    -0.06092143 -0.04552287</code></pre>
<p>The confidence intervals are, again, ‘clunky’ to describe. What the above table indicates is that, if alternate yous (like in a multiverse) repeated your experiment with the same sample size, you would expect the intercept of the line to lie between 8.25 and 9.16 (3 sf) in 95% of those replicates, and you would expect the slope to vary between -0.0455 and -0.0609. The confidence interval is the scientifically interesting bit rather than the P value.</p>
</div>
<div id="plotting-the-regression-line-and-confidence-intervals" class="section level3 hasAnchor" number="5.2.3">
<h3><span class="header-section-number">5.2.3</span> Plotting the regression line and confidence intervals<a href="glm.html#plotting-the-regression-line-and-confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A regression model (i.e. the linear relationship between the predictor and response variables) allows us to predict values for any value of the predictor, along with confidence levels. We can plot this regression line without too much effort.</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb206-1"><a href="glm.html#cb206-1" aria-hidden="true" tabindex="-1"></a>beetle_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(beetle_lm, <span class="at">interval =</span> <span class="st">&quot;confidence&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb206-2"><a href="glm.html#cb206-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb206-3"><a href="glm.html#cb206-3" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>))</span>
<span id="cb206-4"><a href="glm.html#cb206-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(WeightLoss_Mg <span class="sc">~</span> Humidity, <span class="at">data =</span> beetle_df, </span>
<span id="cb206-5"><a href="glm.html#cb206-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">&quot;Relative humidity (%)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Weight loss (mg)&quot;</span>) </span>
<span id="cb206-6"><a href="glm.html#cb206-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(beetle_df<span class="sc">$</span>Humidity, beetle_pred[, <span class="st">&quot;fit&quot;</span>])</span>
<span id="cb206-7"><a href="glm.html#cb206-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(beetle_df<span class="sc">$</span>Humidity, beetle_pred[, <span class="st">&quot;lwr&quot;</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb206-8"><a href="glm.html#cb206-8" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(beetle_df<span class="sc">$</span>Humidity, beetle_pred[, <span class="st">&quot;upr&quot;</span>], <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:beetle-regline"></span>
<img src="_main_files/figure-html/beetle-regline-1.png" alt="Regression line (solid) with upper and lower 95\% CI (dashed)" width="50%" height="50%" />
<p class="caption">
Figure 5.2: Regression line (solid) with upper and lower 95% CI (dashed)
</p>
</div>
<p>Try generating 90% confidence intervals and add them to the plot.</p>
<p><em>Q178. Which will have the wider interval, a 99.99% interval or a 50% interval and why?</em></p>
<p><em>Q179. Do the confidence intervals in Fig. <a href="glm.html#fig:beetle-regline">5.2</a> run parallel to the regression line?</em></p>
<p><em>Q180. If not, what does this suggest about the degree of confidence you have in values predicted at various points along the line?</em></p>
<p><em>Q181. At what value of relative humidity are your predictions of weight loss likely most accurate?</em></p>
<p>We can make predictions based on our regression line, and put confidence intervals on those predictions. Say we had a relative humidity of 50% in the above example. You could ask for the model-predicted weight loss and you’d want confidence intervals on that prediction.</p>
<div class="sourceCode" id="cb207"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb207-1"><a href="glm.html#cb207-1" aria-hidden="true" tabindex="-1"></a><span class="co"># predict() needs a data.frame with the same predictors used in beetle_lm</span></span>
<span id="cb207-2"><a href="glm.html#cb207-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(beetle_lm, </span>
<span id="cb207-3"><a href="glm.html#cb207-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Humidity =</span> <span class="dv">50</span>), </span>
<span id="cb207-4"><a href="glm.html#cb207-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">&quot;predict&quot;</span>, </span>
<span id="cb207-5"><a href="glm.html#cb207-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##       fit      lwr      upr
## 1 6.04292 5.303471 6.782368</code></pre>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb209-1"><a href="glm.html#cb209-1" aria-hidden="true" tabindex="-1"></a><span class="co"># or more fully:</span></span>
<span id="cb209-2"><a href="glm.html#cb209-2" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(beetle_lm, </span>
<span id="cb209-3"><a href="glm.html#cb209-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">Humidity =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by=</span><span class="dv">25</span>)), </span>
<span id="cb209-4"><a href="glm.html#cb209-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">&quot;predict&quot;</span>, </span>
<span id="cb209-5"><a href="glm.html#cb209-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 8.704027 7.868990 9.539064
## 2 7.373474 6.608630 8.138317
## 3 6.042920 5.303471 6.782368
## 4 4.712366 3.949031 5.475701
## 5 3.381812 2.549540 4.214084</code></pre>
<p>These are prediction intervals and they are broader than confidence intervals. The confidence intervals express your confidence about where the mean regression line would lie (if you went back in time and were somehow able to repeatedly sample from the same population). The prediction interval expresses your confidence about where the <em>values</em> would lie if you went back and repeatedly took an individual of the population at a given value of the predictor (e.g. 50% humidity).
For more kicks, import PhosphateCalibration (1st year practical data) into R and duplicate the following plots and confidence intervals.</p>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb211-1"><a href="glm.html#cb211-1" aria-hidden="true" tabindex="-1"></a>phosphate_df <span class="ot">&lt;-</span> <span class="fu">read_xlsx</span>(<span class="st">&quot;data/Practical_6.xlsx&quot;</span>, <span class="st">&quot;PhosphateCalibration&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<p><img src="_main_files/figure-html/unnamed-chunk-81-1.png" width="50%" height="50%" style="display: block; margin: auto;" /></p>
<pre><code>## 
## Call:
## lm(formula = Absorbance ~ Concentration, data = phosphate_df)
## 
## Residuals:
##         1         2         3         4         5         6 
## -0.001605 -0.001213 -0.003125  0.005355  0.005314 -0.004726 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   0.002605   0.002853   0.913 0.412856    
## Concentration 0.023040   0.001849  12.464 0.000238 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.004823 on 4 degrees of freedom
## Multiple R-squared:  0.9749, Adjusted R-squared:  0.9686 
## F-statistic: 155.3 on 1 and 4 DF,  p-value: 0.0002383</code></pre>
<p><em>Q182. Are you happy with your model assumptions?</em></p>
<p><em>Q183. Write down the regression equation.</em></p>
<p><em>Q184. Determine the confidence interval for the regression line.</em></p>
<p><em>Q185. For a concentration of 0.75 units, what values would you expect (95 times in 100) to see from your experimental set-up?</em></p>
<p>You should get:</p>
<pre><code>##          fit         lwr        upr
## 1 0.01988519 0.005298129 0.03447225</code></pre>
<hr />
</div>
</div>
<div id="conclusions-4" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Conclusions<a href="glm.html#conclusions-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Correlation is a measure of association between two variables. It is appropriate to use correlation to measure this association when one cannot or does not wish to assume that any relationship is causative. Pearson correlation coefficients should only be used where it is fair to assume (by looking at scatter plot) that the relationship is approximatley linear. Where linearity does not apply, attempt to transform one or both of the variables. Where there are outliers (that cannot be removed) or where one is uncertain about some of the data, then non-parametric ranked based correlation coefficients, such as the Spearman coefficient, should be used. As with GLMs, correlation analysis assumes that all points are independent of each other.</p>
<p>Linear regression is one of the most widely used statistical techniques. It is used to examine causal relationships, often where experimental manipulations are conducted. Regression is a general linear model and it lies within the generalised linear model family (GLMs). GLMs allow you to model data that is not normally distributed, including proportions (bounded by 0 and 1), or counts (bounded by 0). Using a GLM is a much better way of analysing these data compared with transforming the response variable or using non-parametric techniques. All members of the GLM family make the assumptions that measurements are independent of each other. Where this assumption fails you can use generalised linear mixed models (GLMMs). Extensions of simple linear regression include multiple regression which examines the influence of two or more continuous variables on a response variable.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="t-test.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multivariate.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/Sz-Tim/H2_DS_practicals/edit/BRANCH/05_glm.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
